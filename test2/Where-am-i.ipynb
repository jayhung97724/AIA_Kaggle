{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIA Week 2 Test - Where am I\n",
    "An image classification task!\n",
    "Using Transfer learning and CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題定義\n",
    "\n",
    "輸入資料是分為的15類不同場所的資料夾，最終任務是分辨 test set 的圖片是在哪裡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 引入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.preprocessing import image # 引入讀取圖片用的類別\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import Xception  #引入能夠架 Xception 的類別"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set from: //data/examples/may_the_4_be_with_u/where_am_i/train\n",
      "testing set from //data/examples/may_the_4_be_with_u/where_am_i/testset\n"
     ]
    }
   ],
   "source": [
    "# 確認資料位置\n",
    "datadir = '//data/examples/may_the_4_be_with_u/where_am_i/' # 全部資料在 GPU server 的位置\n",
    "traindir = datadir + 'train' # 圖片 training set 資料夾\n",
    "testdir = datadir + 'testset'\n",
    "print('training set from: %s\\ntesting set from %s' % (traindir, testdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator\n",
    "因為我們的資料及照片數量不夠多，因此透過[ImageDataGenerator](https://zhuanlan.zhihu.com/p/30197320)基於現有圖片來產生更多圖片。\n",
    "\n",
    "可調的參數有:\n",
    "- `rotation_range`:將圖片隨機選轉$[0,\\theta]$內的角度。\n",
    "- `rescale`：縮小圖片的倍數，通常會使用1/255，因為像素範圍是0~255。\n",
    "- `width_shift_range/height_shift_rang`:水平、鉛直的平移，其參數可以是[0, 1]。\n",
    "- `shear_range`:讓圖片傾斜的比例，讓所有X座標(或是Y座標)保持不變，對應的Y座標(或是X座標)按比例發生平移。\n",
    "- `zoom_range`:此參數可以讓圖片的長或寬進行縮放，可以輸入一個數值或是list，若為數值，則兩軸按同樣比例縮放，若為list[width_zoom_range,height_zoom_range]，則表示寬高進行不同比例縮放。\n",
    "- `horizontal_flip`:若為True，則隨機對圖片進行水平翻轉操作，通常不會進行垂直翻轉，因為圖片若垂直翻轉通常沒有意義。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1/255,\n",
    "                             rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2985 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "利用 flow_from_directory 來讀入訓練資料\n",
    "選擇拿取圖片的資料夾，還有決定圖片讀入的 size、訓練 batch_size\n",
    "'''\n",
    "train_gen = datagen.flow_from_directory(traindir, \n",
    "                                        target_size=(150,150),\n",
    "                                        batch_size=32,\n",
    "                                        class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型\n",
    "### 運用 Transfer Learning\n",
    "利用 Imagenet pretrain 好的 Xception 方法作為 CNN 的底層架構，之後再接上 Fully connected layer 做分類。 \n",
    "須先download weights, 會自動 download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = Xception(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3)) # 引用 Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 1.2306 - acc: 0.6432\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 0.8977 - acc: 0.7359\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 20s 201ms/step - loss: 0.7240 - acc: 0.7790\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 20s 201ms/step - loss: 0.7528 - acc: 0.7774\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 0.7490 - acc: 0.7735\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 20s 204ms/step - loss: 0.7180 - acc: 0.7836\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 20s 204ms/step - loss: 0.6716 - acc: 0.7987\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 20s 201ms/step - loss: 0.6305 - acc: 0.8032\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.6067 - acc: 0.8107\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.6073 - acc: 0.8194\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 0.6649 - acc: 0.7960\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.6205 - acc: 0.8223\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 0.5719 - acc: 0.8322\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 0.5612 - acc: 0.8175\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 0.5206 - acc: 0.8316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9dbc66dba8>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential() # 建一個空的 sequential 模型\n",
    "model.add(conv_base) # 把前面設定好的 Xception 放進模型\n",
    "model.add(layers.Flatten()) # 把 Xception 抽取出的圖片特徵攤平\n",
    "\n",
    "model.add(layers.Dense(512, activation=\"relu\", kernel_initializer='random_normal')) # 通過幾層 Dense 來做分類\n",
    "model.add(layers.Dropout(0.3)) # 加 Dropout 避免 overfitting\n",
    "\n",
    "model.add(layers.Dense(256, activation=\"relu\", kernel_initializer='random_normal')) # 通過幾層 Dense 來做分類\n",
    "model.add(layers.Dropout(0.25)) # 加 Dropout 避免 overfitting\n",
    "\n",
    "model.add(layers.Dense(128, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(15, activation=\"softmax\", kernel_initializer='random_normal'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "\n",
    "model.fit_generator(train_gen, steps_per_epoch=100, epochs=15) # 用前面建好的 generator 做訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 5, 5, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 512)               26214912  \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 15)                1935      \n",
      "=================================================================\n",
      "Total params: 47,242,551\n",
      "Trainable params: 47,188,023\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料預測\n",
    "讀入測試資料並做預測，注意：測試資料就不用做擴增了，且記得把圖片的 size 跟 scale 變得跟訓練資料一樣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [] # 用來存圖片檔名\n",
    "class_list = [] # 用來存分類結果\n",
    "submission_example = pandas.read_csv(\"./img-submission.csv\", header=0)\n",
    "submission_example = submission_example[\"id\"]\n",
    "for i in submission_example:\n",
    "    i = i + \".jpg\"\n",
    "    file_name = os.path.join(testdir, i)\n",
    "    img = image.load_img(file_name, target_size=(150, 150)) # 讀取圖片並調整 size\n",
    "    img_array = image.img_to_array(img) # 將圖片轉成陣列\n",
    "    img_array = img_array/255 # 跟訓練資料一樣做 rescale\n",
    "    img_array = img_array.reshape((1,) + img_array.shape) # reshape 成模型能吃的形狀\n",
    "    class_predict = model.predict_classes(img_array) # 對圖片做類別預測\n",
    "    id_list.append(i[:-4]) # 把圖片檔名後的 .jpg 拿掉\n",
    "    class_list.append(class_predict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "上傳前需注意，使用 ImageDataGenerator 產生的 labelencoder 順序跟 mid_term_mapping.txt 文件順序不一樣，所以需要轉換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALsuburb</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARoffice</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bedroom</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coast</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>highway</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>industrial</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>insidecity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>livingroom</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mountain</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>opencountry</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>store</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>street</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tallbuilding</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           place  index\n",
       "0      CALsuburb      9\n",
       "1      PARoffice      7\n",
       "2        bedroom     12\n",
       "3          coast     10\n",
       "4         forest      4\n",
       "5        highway     14\n",
       "6     industrial      2\n",
       "7     insidecity      3\n",
       "8        kitchen      0\n",
       "9     livingroom      5\n",
       "10      mountain      8\n",
       "11   opencountry      6\n",
       "12         store     11\n",
       "13        street      1\n",
       "14  tallbuilding     13"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelmap = pd.read_csv(datadir + 'mid_term_mapping.txt', names=['place','index'])\n",
    "labelmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kitchen', 'street', 'industrial', 'insidecity', 'forest', 'livingroom', 'opencountry', 'PARoffice', 'mountain', 'CALsuburb', 'coast', 'store', 'bedroom', 'tallbuilding', 'highway']\n"
     ]
    }
   ],
   "source": [
    "sortlabel = labelmap.sort_values(by='index')\n",
    "targetlist = sortlabel.place.as_matrix().tolist()\n",
    "print(targetlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CALsuburb': 0,\n",
       " 'PARoffice': 1,\n",
       " 'bedroom': 2,\n",
       " 'coast': 3,\n",
       " 'forest': 4,\n",
       " 'highway': 5,\n",
       " 'industrial': 6,\n",
       " 'insidecity': 7,\n",
       " 'kitchen': 8,\n",
       " 'livingroom': 9,\n",
       " 'mountain': 10,\n",
       " 'opencountry': 11,\n",
       " 'store': 12,\n",
       " 'street': 13,\n",
       " 'tallbuilding': 14}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.class_indices # 觀察每個類別的labelencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將 predict 的 class 轉成 submission class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_class = train_gen.class_indices\n",
    "inverdict = {k:v for v,k in gen_class.items()} # 將key與value對調\n",
    "class_list_name = [inverdict[k] for k in class_list] # 透過對調的dict將class轉回placename\n",
    "final_class = [targetlist.index(k) for k in class_list_name] # 轉換為正確的submission index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pandas.DataFrame({\"id\": id_list, \"class\": final_class}) # 建 DataFrame 存放結果\n",
    "submission.to_csv(\"submission.csv\", index = False, columns = [\"id\", \"class\"]) # 輸出結果到 csv 檔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My result:\n",
    "![]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
